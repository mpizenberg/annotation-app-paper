@inproceedings{korinke_exploring_2015,
	address = {New York, NY, USA},
	series = {{MUM} '15},
	title = {Exploring {Touch} {Interaction} {Methods} for {Image} {Segmentation} on {Mobile} {Devices}},
	isbn = {978-1-4503-3605-5},
	url = {http://doi.acm.org/10.1145/2836041.2836049},
	doi = {10.1145/2836041.2836049},
	abstract = {Photo taking is more and more moving to mobile devices. With this transition, we observe that consumers are also directly editing and sharing photos. Editing of the whole image became very popular, for example with the filters Instagram offers. Some effects, however, require to edit a specific object of an image and for this an interactive segmentation is needed. This process is still tedious, as existing segmentation approaches focus on the algorithms rather than on the input methods. This paper explores different interaction techniques for image segmentation on mobile devices. We conducted two studies. The first to identify intuitive input methods and the second to evaluate the findings of the first study. As a result, we identified preferred gestures for the initial step to select a foreground object in an interactive image segmentation process. The results give first insights which input methods users intuitively use, how the users behave and what are the problems of the methods. This insights should be taken in consideration by the development of new interactive segmentation algorithms for mobile touch-based devices.},
	urldate = {2016-10-12},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
	publisher = {ACM},
	author = {Korinke, Christoph and Worzyk, Nils Steffen and Boll, Susanne},
	year = {2015},
	keywords = {bounding box, colouring, input methods evaluation, interactive image segmentation, mobile touch-based devices, outline},
	pages = {84--93},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/V4Z9PEZK/Korinke et al. - 2015 - Exploring Touch Interaction Methods for Image Segm.pdf:application/pdf}
}

@inproceedings{korinke_intuitive_2015,
	address = {New York, NY, USA},
	series = {{MM} '15},
	title = {Intuitive {Input} {Methods} for {Interactive} {Segmentation} on {Mobile} {Touch}-{Based} {Devices}},
	isbn = {978-1-4503-3459-4},
	url = {http://doi.acm.org/10.1145/2733373.2807993},
	doi = {10.1145/2733373.2807993},
	abstract = {Existing interactive image segmentation approaches mainly focus on the algorithms rather than the input methods. The literature regarding the input methods is mainly applied to desktop PCs. However, there is a transition to mobile touch-based devices. In this paper we describe our approach to identify a set of intuitive input methods for interactive segmentation on mobile devices. Preliminary results of two user studies are presented. A description of our planned research is given, divided into initial and refinement input methods and the exploitation of the input for segmentation algorithms.},
	urldate = {2016-10-12},
	booktitle = {Proceedings of the 23rd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Korinke, Christoph},
	year = {2015},
	keywords = {input methods evaluation, interactive image segmentation, mobile touch-based devices},
	pages = {645--648},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/6PE7B6ZX/Korinke - 2015 - Intuitive Input Methods for Interactive Segmentati.pdf:application/pdf}
}


@inproceedings{batra_icoseg:_2010,
	title = {{iCoseg}: {Interactive} co-segmentation with intelligent scribble guidance},
	shorttitle = {{iCoseg}},
	doi = {10.1109/CVPR.2010.5540080},
	abstract = {This paper presents an algorithm for Interactive Co-segmentation of a foreground object from a group of related images. While previous approaches focus on unsupervised co-segmentation, we use successful ideas from the interactive object-cutout literature. We develop an algorithm that allows users to decide what foreground is, and then guide the output of the co-segmentation algorithm towards it via scribbles. Interestingly, keeping a user in the loop leads to simpler and highly parallelizable energy functions, allowing us to work with significantly more images per group. However, unlike the interactive single image counterpart, a user cannot be expected to exhaustively examine all cutouts (from tens of images) returned by the system to make corrections. Hence, we propose iCoseg, an automatic recommendation system that intelligently recommends where the user should scribble next. We introduce and make publicly available the largest co-segmentation datasetyet, the CMU-Cornell iCoseg Dataset, with 38 groups, 643 images, and pixelwise hand-annotated groundtruth. Through machine experiments and real user studies with our developed interface, we show that iCoseg can intelligently recommend regions to scribble on, and users following these recommendations can achieve good quality cutouts with significantly lower time and effort than exhaustively examining all cutouts.},
	booktitle = {2010 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Batra, D. and Kowdle, A. and Parikh, D. and Luo, J. and Chen, T.},
	month = jun,
	year = {2010},
	keywords = {automatic recommendation system, energy functions, Facebook, foreground object, iCoseg, Image segmentation, intelligent scribble guidance, Intelligent systems, interactive cosegmentation, interactive object-cutout literature, Iterative algorithms, Machine intelligence, recommender systems, Smart pixels, unsupervised cosegmentation},
	pages = {3169--3176},
	file = {IEEE Xplore Abstract Record:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/HEEH2ZUF/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/VI3N8PW7/Batra et al. - 2010 - iCoseg Interactive co-segmentation with intellige.pdf:application/pdf}
}

@inproceedings{collins_random_2012,
	title = {Random walks based multi-image segmentation: {Quasiconvexity} results and {GPU}-based solutions},
	shorttitle = {Random walks based multi-image segmentation},
	doi = {10.1109/CVPR.2012.6247859},
	abstract = {We recast the Cosegmentation problem using Random Walker (RW) segmentation as the core segmentation algorithm, rather than the traditional MRF approach adopted in the literature so far. Our formulation is similar to previous approaches in the sense that it also permits Cosegmentation constraints (which impose consistency between the extracted objects from ≥ 2 images) using a nonparametric model. However, several previous nonparametric cosegmentation methods have the serious limitation that they require adding one auxiliary node (or variable) for every pair of pixels that are similar (which effectively limits such methods to describing only those objects that have high entropy appearance models). In contrast, our proposed model completely eliminates this restrictive dependence - the resulting improvements are quite significant. Our model further allows an optimization scheme exploiting quasiconvexity for model-based segmentation with no dependence on the scale of the segmented foreground. Finally, we show that the optimization can be expressed in terms of linear algebra operations on sparse matrices which are easily mapped to GPU architecture. We provide a highly specialized CUDA library for Cosegmentation exploiting this special structure, and report experimental results showing these advantages.},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Collins, M. D. and Xu, J. and Grady, L. and Singh, V.},
	month = jun,
	year = {2012},
	keywords = {Computational modeling, cosegmentation constraint, cosegmentation problem, CUDA library, entropy, entropy appearance model, Face, Feature extraction, foreground segmentation, GPU architecture, GPU-based solution, Graphics processing unit, graphics processing units, Histograms, Image segmentation, linear algebra, model-based segmentation, multiimage segmentation, nonparametric cosegmentation, nonparametric model, object extraction, optimisation, Optimization, optimization scheme, quasiconvexity, random processes, random walker, RW segmentation, sparse matrices, sparse matrix},
	pages = {1656--1663},
	file = {IEEE Xplore Abstract Record:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/73CWXRIU/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/9GGMD57E/Collins et al. - 2012 - Random walks based multi-image segmentation Quasi.pdf:application/pdf}
}

@article{dong_interactive_2015,
	title = {Interactive {Cosegmentation} {Using} {Global} and {Local} {Energy} {Optimization}},
	volume = {24},
	issn = {1057-7149},
	doi = {10.1109/TIP.2015.2456636},
	abstract = {We propose a novel interactive cosegmentation method using global and local energy optimization. The global energy includes two terms: 1) the global scribbled energy and 2) the interimage energy. The first one utilizes the user scribbles to build the Gaussian mixture model and improve the cosegmentation performance. The second one is a global constraint, which attempts to match the histograms of common objects. To minimize the local energy, we apply the spline regression to learn the smoothness in a local neighborhood. This energy optimization can be converted into a constrained quadratic programming problem. To reduce the computational complexity, we propose an iterative optimization algorithm to decompose this optimization problem into several subproblems. The experimental results show that our method outperforms the state-of-the-art unsupervised cosegmentation and interactive cosegmentation methods on the iCoseg and MSRC benchmark data sets.},
	number = {11},
	journal = {IEEE Transactions on Image Processing},
	author = {Dong, X. and Shen, J. and Shao, L. and Yang, M. H.},
	month = nov,
	year = {2015},
	keywords = {Co-segmentation, Gaussian mixture model, Gaussian processes, global scribbled energy, histogram matching, Histograms, iCoseg, Image color analysis, Image segmentation, interactive cosegmentation methods, interimage energy, iterative methods, iterative optimization algorithm, local spline regression, Minimization, mixture models, MSRC benchmark data sets, Optimization, quadratic programming, quadratic programming problem, spline regression, Splines (mathematics), unsupervised cosegmentation},
	pages = {3966--3977},
	file = {IEEE Xplore Abstract Record:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/7XP66DK2/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/5KVBWDJD/Dong et al. - 2015 - Interactive Cosegmentation Using Global and Local .pdf:application/pdf}
}


@inproceedings{rother_grabcut:_2004,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '04},
	title = {"{GrabCut}": {Interactive} {Foreground} {Extraction} {Using} {Iterated} {Graph} {Cuts}},
	shorttitle = {"{GrabCut}"},
	url = {http://doi.acm.org/10.1145/1186562.1015720},
	doi = {10.1145/1186562.1015720},
	abstract = {The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for "border matting" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.},
	urldate = {2016-10-12},
	booktitle = {{ACM} {SIGGRAPH} 2004 {Papers}},
	publisher = {ACM},
	author = {Rother, Carsten and Kolmogorov, Vladimir and Blake, Andrew},
	year = {2004},
	keywords = {Alpha Matting, Foreground extraction, Graph Cuts, Image Editing, interactive image segmentation},
	pages = {309--314},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/U2MNPCUZ/Rother et al. - 2004 - GrabCut Interactive Foreground Extraction Using.pdf:application/pdf}
}

@inproceedings{carlier_clickncut:_2014,
	address = {New York, NY, USA},
	series = {{CrowdMM} '14},
	title = {Click'{N}'{Cut}: {Crowdsourced} {Interactive} {Segmentation} with {Object} {Candidates}},
	isbn = {978-1-4503-3128-9},
	shorttitle = {Click'{N}'{Cut}},
	url = {http://doi.acm.org/10.1145/2660114.2660125},
	doi = {10.1145/2660114.2660125},
	abstract = {This paper introduces Click'n'Cut, a novel web tool for interactive object segmentation designed for crowdsourcing tasks. Click'n'Cut combines bounding boxes and clicks generated by workers to obtain accurate object segmentations. These segmentations are created by combining precomputed object candidates in a light computational fashion that allows an immediate response from the interface. Click'n'Cut has been tested with a crowdsourcing campaign to annotate images from publicly available datasets. Results are competitive with state-of-the-art approaches, especially in terms of time needed to converge to a high quality segmentation.},
	urldate = {2016-10-15},
	booktitle = {Proceedings of the 2014 {International} {ACM} {Workshop} on {Crowdsourcing} for {Multimedia}},
	publisher = {ACM},
	author = {Carlier, Axel and Charvillat, Vincent and Salvador, Amaia and Giro-i-Nieto, Xavier and Marques, Oge},
	year = {2014},
	keywords = {crowdsourcing, object candidates, object segmentation},
	pages = {53--56},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/8HDBXXI5/Carlier et al. - 2014 - Click'N'Cut Crowdsourced Interactive Segmentation.pdf:application/pdf}
}

@article{mortensen_interactive_1998,
	title = {Interactive {Segmentation} with {Intelligent} {Scissors}},
	volume = {60},
	issn = {1077-3169},
	url = {http://www.sciencedirect.com/science/article/pii/S1077316998904804},
	doi = {10.1006/gmip.1998.0480},
	abstract = {We present a new, interactive tool calledIntelligent Scissorswhich we use for image segmentation. Fully automated segmentation is an unsolved problem, while manual tracing is inaccurate and laboriously unacceptable. However, Intelligent Scissors allow objects within digital images to be extracted quickly and accurately using simple gesture motions with a mouse. When the gestured mouse position comes in proximity to an object edge, alive-wire boundary“snaps” to, and wraps around the object of interest. Live-wire boundary detection formulates boundary detection as an optimal path search in a weighted graph. Optimal graph searching provides mathematically piece-wise optimal boundaries while greatly reducing sensitivity to local noise or other intervening structures. Robustness is further enhanced withon-the-fly trainingwhich causes the boundary to adhere to the specific type of edge currently being followed, rather than simply the strongest edge in the neighborhood.Boundary coolingautomatically freezes unchanging segments and automates input of additional seed points. Cooling also allows the user to be much more free with the gesture path, thereby increasing the efficiency and finesse with which boundaries can be extracted.},
	number = {5},
	urldate = {2016-10-15},
	journal = {Graphical Models and Image Processing},
	author = {Mortensen, Eric N. and Barrett, William A.},
	month = sep,
	year = {1998},
	pages = {349--384},
	file = {ScienceDirect Snapshot:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/U926TPVN/S1077316998904804.html:text/html}
}

@inproceedings{boykov_interactive_2001,
	title = {Interactive graph cuts for optimal boundary amp; region segmentation of objects in {N}-{D} images},
	volume = {1},
	doi = {10.1109/ICCV.2001.937505},
	abstract = {In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as “object” or “background” to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both “object” and “background” segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm},
	booktitle = {Eighth {IEEE} {International} {Conference} on {Computer} {Vision}, 2001. {ICCV} 2001. {Proceedings}},
	author = {Boykov, Y. Y. and Jolly, M. P.},
	year = {2001},
	keywords = {Biomedical imaging, computational geometry, Cost function, Educational institutions, Gestalt example, globally optimal segmentation, hard constraints, Image segmentation, interactive graph cuts, interactive segmentation, interactive systems, Level set, max-flow algorithm, medical image segmentation, N-D images, N-dimensional images, optimal boundary \& region segmentation, Region 5, soft constraints, Topology, Visualization},
	pages = {105--112 vol.1},
	file = {IEEE Xplore Abstract Record:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/VVXAINTP/937505.html:text/html}
}

@inproceedings{irshad2014crowdsourcing,
  title={Crowdsourcing image annotation for nucleus detection and segmentation in computational pathology: evaluating experts, automated methods, and the crowd.},
  author={Irshad, Humayun and Montaser-Kouhsari,  Laleh and Waltz, Gail and Bucur, Octavian and Nowak, JA and Dong,  Fei and Knoblauch,  Nicholas W and Beck, Andrew H},
  booktitle={Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
  pages={294--305},
  year={2014},
  organization={NIH Public Access}
}

@inproceedings{chavez2013crowdsourcing,
  title={A crowdsourcing web platform-hip joint segmentation by non-expert contributors},
  author={Ch{\'a}vez-Arag{\'o}n, Alberto and Lee, Won-Sook and Vyas, Aseem},
  booktitle={Medical Measurements and Applications Proceedings (MeMeA), 2013 IEEE International Symposium on},
  pages={350--354},
  year={2013},
  organization={IEEE}
}

@inproceedings{gurari2015collect,
  title={How to collect segmentations for biomedical images? A benchmark evaluating the performance of experts, crowdsourced non-experts, and algorithms},
  author={Gurari, Danna and Theriault, Diane and Sameki, Mehrnoosh and Isenberg, Brett and Pham, Tuan A and Purwada, Alberto and Solski, Patricia and Walker, Matthew and Zhang, Chentian and Wong, Joyce Y and others},
  booktitle={Applications of Computer Vision (WACV), 2015 IEEE Winter Conference on},
  pages={1169--1176},
  year={2015},
  organization={IEEE}
}

@article{russell2008labelme,
  title={LabelMe: a database and web-based tool for image annotation},
  author={Russell, Bryan C and Torralba, Antonio and Murphy, Kevin P and Freeman, William T},
  journal={International journal of computer vision},
  volume={77},
  number={1},
  pages={157--173},
  year={2008},
  publisher={Springer}
}

@inproceedings{mortensen1995intelligent,
  title={Intelligent scissors for image composition},
  author={Mortensen, Eric N and Barrett, William A},
  booktitle={Proceedings of the 22nd annual conference on Computer graphics and interactive techniques},
  pages={191--198},
  year={1995},
  organization={ACM}
}

@inproceedings{friedland2005siox,
  title={Siox: Simple interactive object extraction in still images},
  author={Friedland, Gerald and Jantz, Kristian and Rojas, Raul},
  booktitle={Multimedia, Seventh IEEE International Symposium on},
  pages={7--pp},
  year={2005},
  organization={IEEE}
}

@article{mcguinness2010comparative,
  title={A comparative evaluation of interactive segmentation algorithms},
  author={McGuinness, Kevin and O’connor, Noel E},
  journal={Pattern Recognition},
  volume={43},
  number={2},
  pages={434--444},
  year={2010},
  publisher={Elsevier}
}

@article{salembier2000binary,
  title={Binary partition tree as an efficient representation for image processing, segmentation, and information retrieval},
  author={Salembier, Philippe and Garrido, Luis},
  journal={IEEE transactions on Image Processing},
  volume={9},
  number={4},
  pages={561--576},
  year={2000},
  publisher={IEEE}
}

@article{carlier2016assessment,
  title={Assessment of crowdsourcing and gamification loss in user-assisted object segmentation},
  author={Carlier, Axel and Salvador, Amaia and Cabezas, Ferran and Giro-i-Nieto, Xavier and Charvillat, Vincent and Marques, Oge},
  journal={Multimedia tools and applications},
  volume={75},
  number={23},
  pages={15901--15928},
  year={2016},
  publisher={Springer}
}

@article{blum1978shape,
  title={Shape description using weighted symmetric axis features},
  author={Blum, Harry and Nagel, Roger N},
  journal={Pattern recognition},
  volume={10},
  number={3},
  pages={167--180},
  year={1978},
  publisher={Elsevier}
}

@article{comaniciu2002mean,
  title={Mean shift: A robust approach toward feature space analysis},
  author={Comaniciu, Dorin and Meer, Peter},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={24},
  number={5},
  pages={603--619},
  year={2002},
  publisher={IEEE}
}

@book{nielsen1994usability,
  title={Usability engineering},
  author={Nielsen, Jakob},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3431--3440},
  year={2015}
}

@article{liu2017active,
  title={Active deep learning for classification of hyperspectral images},
  author={Liu, Peng and Zhang, Hui and Eom, Kie B},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={10},
  number={2},
  pages={712--724},
  year={2017},
  publisher={IEEE}
}

@inproceedings{papandreou2015weakly,
  title={Weakly-and Semi-Supervised Learning of a Deep Convolutional Network for Semantic Image Segmentation},
  author={Papandreou, George and Chen, Liang-Chieh and Murphy, Kevin P and Yuille, Alan L},
  booktitle={Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
  pages={1742--1750},
  year={2015},
  organization={IEEE Computer Society}
}

@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={88},
  number={2},
  pages={303--338},
  year={2010},
  publisher={Springer}
}

@inproceedings{wang2007soft,
  title={Soft scissors: an interactive tool for realtime high quality matting},
  author={Wang, Jue and Agrawala, Maneesh and Cohen, Michael F},
  booktitle={ACM Transactions on Graphics (TOG)},
  volume={26},
  number={3},
  pages={9},
  year={2007},
  organization={ACM}
}

@inproceedings{czaplicki2013asynchronous,
  title={Asynchronous functional reactive programming for GUIs},
  author={Czaplicki, Evan and Chong, Stephen},
  booktitle={ACM SIGPLAN Notices},
  volume={48},
  number={6},
  pages={411--422},
  year={2013},
  organization={ACM}
}

@misc{czaplicki2017elm,
  title={Elm},
  author={Czaplicki, Evan},
  year={2017},
  howpublished = {\url{http://elm-lang.org/}},
  note = {Accessed: 2018-05-20}
}

@misc{labelbox,
  title={Labelbox},
  year={2018},
  howpublished = {\url{https://www.labelbox.com/}},
  note = {Accessed: 2018-05-20}
}

@misc{dataturks,
  title={Dataturks},
  year={2018},
  howpublished = {\url{https://dataturks.com/}},
  note = {Accessed: 2018-05-20}
}

@misc{dutta2016via,
  author = "Dutta, A. and Gupta, A. and Zissermann, A.",
  title = "{VGG} Image Annotator ({VIA})",
  year = "2016",
  howpublished = "http://www.robots.ox.ac.uk/~vgg/software/via/",
  note = "Accessed: 2018-05-20"
}

@misc{annotationpackage,
  title={Image annotation package},
  year={2018},
  howpublished = {\url{https://github.com/mpizenberg/elm-image-annotation}},
  note = {Accessed: 2018-05-20}
}

@misc{annotationappgithub,
  title={Application source code},
  year={2018},
  howpublished = {\url{https://github.com/mpizenberg/annotation-app}},
  note = {Accessed: 2018-05-20}
}

@misc{annotationappdoc,
  title={Application documentation},
  year={2018},
  howpublished = {\url{https://reva-n7.gitbook.io/annotation-app/}},
  note = {Accessed: 2018-05-20}
}
